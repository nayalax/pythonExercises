{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk import ne_chunk\n",
    " \n",
    "# Descargar recursos adicionales\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fragmento de texto\n",
    "texto = \"\"\"Ralph sat in the hot sand, touching the shell, smiling and nodding his head to the cries of admiration.\n",
    "Around them, the children began to settle and pay attention.\n",
    "It was as if they had heard for the first time the brilliant idea of democracy.\"\"\"\n",
    " \n",
    "# Tokenización: Divide el texto en oraciones y luego en palabras\n",
    "oraciones = sent_tokenize(texto)\n",
    "palabras = [word_tokenize(oracion) for oracion in oraciones]\n",
    " \n",
    "# Etiquetado de Partes del Discurso (POS Tagging)\n",
    "etiquetas_pos = [pos_tag(palabra) for palabra in palabras]\n",
    " \n",
    "# Lematización\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemas = [[lemmatizer.lemmatize(word) for word, tag in palabra] for palabra in etiquetas_pos]\n",
    " \n",
    "# Análisis de Sentimientos\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentimientos = [sia.polarity_scores(oracion) for oracion in oraciones]\n",
    " \n",
    "# Extracción de Entidades Nombradas (NER)\n",
    "entidades = [ne_chunk(pos_tag(word_tokenize(oracion))) for oracion in oraciones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir resultados\n",
    "print(\"Oraciones tokenizadas:\")\n",
    "print(oraciones)\n",
    "print(\"\\nPalabras tokenizadas:\")\n",
    "print(palabras)\n",
    "print(\"\\nEtiquetas POS:\")\n",
    "print(etiquetas_pos)\n",
    "print(\"\\nLemas:\")\n",
    "print(lemas)\n",
    "print(\"\\nAnálisis de Sentimientos:\")\n",
    "print(sentimientos)\n",
    "print(\"\\nEntidades Nombradas:\")\n",
    "for entidad in entidades:\n",
    "    print(entidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
