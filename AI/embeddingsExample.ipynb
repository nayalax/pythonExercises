{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nicholas.ayala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nicholas.ayala\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de 'python': [ 5.6248726e-03  5.4952400e-03  1.8312103e-03  5.7466258e-03\n",
      " -8.9694280e-03  6.5586166e-03  9.2282193e-03 -4.2049107e-03\n",
      "  1.6067064e-03 -5.2374001e-03  1.0574245e-03  2.7697671e-03\n",
      "  8.1609664e-03  5.4541335e-04  2.5559543e-03  1.2965827e-03\n",
      "  8.4043918e-03 -5.7061240e-03 -6.2658801e-03 -3.6310293e-03\n",
      " -2.3045607e-03  5.0418666e-03 -8.1245182e-03 -2.8300399e-03\n",
      " -8.1986710e-03  5.1500006e-03 -2.5678228e-03 -9.0677571e-03\n",
      "  4.0718429e-03  9.0164822e-03 -3.0370811e-03 -5.8357748e-03\n",
      "  3.0194754e-03 -4.3421809e-04 -9.9786399e-03  8.4149186e-03\n",
      " -7.3371446e-03 -4.9352939e-03 -2.6536766e-03 -5.4505393e-03\n",
      "  1.7142271e-03  9.7128889e-03  4.5755468e-03  8.0884127e-03\n",
      " -4.6950090e-04  6.4095791e-04 -2.6666471e-03 -8.7800510e-03\n",
      "  3.4330073e-03  2.0929975e-03 -9.4188582e-03 -4.9675275e-03\n",
      " -9.7347703e-03 -5.7200622e-03  4.0658559e-03  8.6448863e-03\n",
      "  4.1154488e-03  2.3923100e-03  8.1495717e-03 -1.1160529e-03\n",
      " -1.3966425e-03 -8.7489663e-03 -1.2374498e-04 -2.5661718e-03\n",
      "  3.8463366e-04  7.2807847e-03 -7.0439246e-03 -3.9502140e-03\n",
      " -6.6679693e-03 -3.5409995e-03 -3.3156339e-03  2.1375122e-03\n",
      "  3.3290237e-03 -4.9588955e-03 -4.5465976e-03  1.1394777e-03\n",
      "  5.4562488e-03  5.3757089e-03 -2.9697742e-03 -4.2660725e-03\n",
      " -5.6174621e-03 -5.4336904e-04  1.9437101e-03  1.5291378e-03\n",
      "  7.3529207e-03 -2.7306937e-03 -6.6005552e-05 -5.5267839e-03\n",
      " -1.1686685e-03 -7.7093611e-03 -9.5921173e-04  1.3082738e-03\n",
      " -8.5939197e-03  8.7500885e-03 -9.2058238e-03 -9.6276049e-03\n",
      " -8.5070226e-03  7.3113195e-03  5.4671685e-03  9.2484709e-03]\n",
      "Palabras similares a 'python': [('learning', 0.3190315067768097), ('identificar', 0.18888963758945465), (\"'ver\", 0.16219891607761383), ('emplean', 0.14646722376346588), ('aprendizaje', 0.12758980691432953), ('natural', 0.1275448501110077), ('fortalece', 0.12244671583175659), ('ciudades', 0.12202563136816025), ('machine', 0.11061759293079376), ('complejos', 0.11045210808515549)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Ejemplo de datos: frases sobre tecnología\n",
    "datos = [\n",
    "    \"La inteligencia artificial está transformando el mundo.\",\n",
    "    \"Las redes neuronales pueden identificar patrones complejos.\",\n",
    "    \"El aprendizaje profundo es una técnica clave en IA.\",\n",
    "    \"Python es popular en la ciencia de datos.\",\n",
    "    \"Los algoritmos de machine learning mejoran con el tiempo.\",\n",
    "    \"La visión por computadora permite a las máquinas 'ver'.\",\n",
    "    \"El procesamiento de lenguaje natural facilita la interacción humano-máquina.\",\n",
    "    \"Los sistemas de recomendación personalizan la experiencia en línea.\",\n",
    "    \"La robótica utiliza IA para realizar tareas complejas.\",\n",
    "    \"Los vehículos autónomos emplean IA para navegar.\",\n",
    "    \"La seguridad informática se fortalece mediante el uso de IA.\",\n",
    "    \"La inteligencia artificial contribuye al desarrollo de la medicina personalizada.\",\n",
    "    \"Las ciudades inteligentes utilizan IA para mejorar la vida urbana.\",\n",
    "    \"La IA en la agricultura ayuda a optimizar la producción.\"\n",
    "]\n",
    "\n",
    "# Lista de stopwords en español\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "# Tokenización de las frases y eliminación de stopwords\n",
    "datos_tokenizados = [[palabra for palabra in word_tokenize(frase.lower()) if palabra not in stop_words]\n",
    "                     for frase in datos]\n",
    "\n",
    "# Entrenamiento del modelo Word2Vec\n",
    "modelo = Word2Vec(sentences=datos_tokenizados, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Obtener el vector de una palabra\n",
    "vector_palabra = modelo.wv['python']\n",
    "\n",
    "# Encontrar palabras similares\n",
    "palabras_similares = modelo.wv.most_similar('python')\n",
    "\n",
    "print(\"Vector de 'python':\", vector_palabra)\n",
    "print(\"Palabras similares a 'python':\", palabras_similares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_excel('excel_movies.xlsx')\n",
    "df['overview'] = df['overview'].fillna(' ').astype('str')\n",
    "# Preprocesamiento básico sin dividir en palabras\n",
    "df['overview_clean'] = df['overview'].str.lower()  # Convertir a minúsculas\n",
    "\n",
    "# Tokenización por frases\n",
    "df['overview_frases'] = df['overview_clean'].apply(lambda x: sent_tokenize(x))\n",
    "\n",
    "# Aplanar la lista de frases para entrenar Word2Vec, que espera una lista de palabras por frase/documento\n",
    "descripciones_frases = [word_tokenize(frase) for lista_frases in df['overview_frases'] for frase in lista_frases]\n",
    "\n",
    "# Inicializar el modelo Word2Vec sin entrenar\n",
    "modelo_word2vec = Word2Vec(vector_size=300, window=10, min_count=1, epochs=15, workers=4)\n",
    "modelo_word2vec.build_vocab(descripciones_frases)\n",
    "modelo_word2vec.train(descripciones_frases, total_examples=modelo_word2vec.corpus_count, epochs=modelo_word2vec.epochs)\n",
    "\n",
    "def obtener_vector_pelicula(frases_pelicula, modelo_param):\n",
    "    vectores = [modelo_param.wv[word] for frase in frases_pelicula for word in frase if word in modelo_param.wv]\n",
    "    if not vectores:\n",
    "        return np.zeros(modelo_param.vector_size)\n",
    "    vector_pelicula = np.mean(vectores, axis=0)\n",
    "    return vector_pelicula\n",
    "\n",
    "# Generar vectores para cada conjunto de frases de películas usando Word2Vec\n",
    "vectores_peliculas_word2vec = np.array([obtener_vector_pelicula(frases, modelo_word2vec) for frases in df['overview_frases']])\n",
    "\n",
    "# Función para encontrar películas similares\n",
    "def peliculas_similares(index, vectores_peliculas_param):\n",
    "    similitudes = cosine_similarity([vectores_peliculas_param[index]], vectores_peliculas_param)[0]\n",
    "    indices_similares = np.argsort(similitudes)[::-1][1:6]\n",
    "    return [(indice, similitudes[indice]) for indice in indices_similares]\n",
    "\n",
    "# Ejemplo de uso con Word2Vec\n",
    "indice_pelicula = 867  # Cambiar por el índice de la película de interés\n",
    "print(f\"... buscando similares a '{df.iloc[indice_pelicula]['title']}' con Word2Vec:\")\n",
    "peliculas_sim = peliculas_similares(indice_pelicula, vectores_peliculas_word2vec)\n",
    "for pelicula_idx in peliculas_sim:\n",
    "    print(df.iloc[pelicula_idx[0]]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Crear un stemmer en español\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# Lista de stopwords en español\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    # Tokenizar el texto\n",
    "    palabras = word_tokenize(texto)\n",
    "    # Quitar puntuación y stopwords\n",
    "    palabras_filtradas = [stemmer.stem(palabra.lower()) for palabra in palabras if palabra.isalpha() and palabra.lower() not in stop_words]\n",
    "    return palabras_filtradas\n",
    "\n",
    "# Ejemplo de datos: nombres de películas y sus descripciones\n",
    "peliculas = [\n",
    "    \"El Padrino: Don Vito Corleone es el respetado y temido jefe de una de las cinco familias de la mafia de Nueva York en los años 40. El hombre tiene cuatro hijos: Connie, Sonny, Fredo y Michael, que no quiere saber nada de los negocios sucios de su padre. Cuando otro capo, Sollozzo, intenta asesinar a Corleone, empieza una cruenta lucha entre los distintos clanes.\",\n",
    "    \"Toy Story: Los juguetes de Andy, un niño de seis años, temen que un nuevo regalo les sustituya en el corazón de su dueño. Woody, un vaquero que ha sido hasta ahora el juguete favorito, trata de tranquilizarlos hasta que aparece Buzz Lightyear. Lo peor es que el arrogante Buzz se cree que es una auténtico astronauta en plena misión para regresar a su planeta.\",\n",
    "    \"Forrest Gump: Sentado en un banco en Savannah, Georgia, Forrest Gump espera al autobús. Mientras éste tarda en llegar, el joven cuenta su vida a las personas que se sientan a esperar con él. Aunque sufre un pequeño retraso mental, esto no le impide hacer cosas maravillosas. Sin entender del todo lo que sucede a su alrededor, Forrest toma partido en los eventos más importantes de la historia de los Estados Unidos.\",\n",
    "    \"La lista de Schindler: Oskar Schindler, un empresario alemán, salva la vida de más de mil judíos polacos durante el Holocausto al emplearlos en sus fábricas. La película narra su evolución desde un oportunista indiferente a un héroe improbable y compasivo.\",\n",
    "    \"El Señor de los Anillos: La Comunidad del Anillo: En la Tierra Media, Frodo Bolsón, un joven hobbit, es encargado de destruir un anillo poderoso y malvado antes de que caiga en manos del oscuro señor Sauron. La formación de la Comunidad del Anillo tiene como objetivo ayudar a Frodo en su misión.\",\n",
    "    \"Matrix: Thomas A. Anderson es un programador de día y un hacker llamado Neo de noche. Sospechando que algo anda mal con el mundo, Neo descubre la verdad sobre la Matrix, una simulación virtual creada para someter a la humanidad, y se une a la lucha contra sus controladores.\",\n",
    "    \"Amelie: En París, Amelie Poulain, una joven camarera, decide cambiar la vida de las personas a su alrededor para mejor, mientras lucha con su propia soledad. Sus buenas acciones provocan una cadena de eventos inesperados.\",\n",
    "    \"Pulp Fiction: Las vidas de dos sicarios, un boxeador, la esposa de un mafioso y dos bandidos se entrelazan en cuatro historias de violencia y redención.\",\n",
    "    \"El club de la lucha: Un empleado de oficina insomne y un carismático vendedor de jabón forman un club de lucha clandestino que se convierte en algo mucho más grande. La película explora temas de consumismo, insatisfacción y la búsqueda de identidad.\",\n",
    "    \"Gladiator: En el año 180, el general romano Maximus Decimus Meridius es traicionado cuando el hijo del emperador asesina a su propio padre y se apodera del trono. Reducido a la esclavitud, Maximus se convierte en gladiador y lucha por su venganza.\",\n",
    "    \"Interestelar: En un futuro cercano, la Tierra está siendo devastada por desastres naturales. Un equipo de astronautas viaja a través de un agujero de gusano en busca de un nuevo hogar para la humanidad. La película explora temas de amor, sacrificio y la lucha por la supervivencia.\"\n",
    "]\n",
    "\n",
    "peliculas_limpia = [limpiar_texto(pelicula) for pelicula in peliculas]\n",
    "# Entrenar el modelo Word2Vec\n",
    "modelo = Word2Vec(peliculas_limpia, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Ejemplo de uso: encontrar palabras similares a 'familia'\n",
    "palabras_similares = modelo.wv.most_similar(stemmer.stem('familia'), topn=5)\n",
    "print(palabras_similares)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
